# Copy this file to `.env` for local development.

# REST API server (scripts/run_api.py, FastAPI)
# Note: if you also run vLLM on port 8000, set ADSP_API_PORT=8080.
ADSP_API_HOST=0.0.0.0
ADSP_API_PORT=8000
ADSP_API_RELOAD=true
ADSP_API_RUN_MODE=uvicorn
ADSP_API_DEBUG=false
ADSP_API_LOG_LEVEL=info
ADSP_API_TITLE=Lavazza AI Personas API
ADSP_API_VERSION=0.1.0

# If true, protected endpoints require X-User and X-Token headers.
ADSP_REQUIRE_AUTH=false

# Application services
ADSP_INGESTION_BUCKET=uploads
ADSP_REPORTS_DIR=reports/api

# Runtime LLM backend:
# - `stub`: no external server required (default)
# - `openai`: call an OpenAI-compatible endpoint (e.g., vLLM)
ADSP_LLM_BACKEND=stub

# OpenAI-compatible runtime model settings (only used when ADSP_LLM_BACKEND=openai)
ADSP_LLM_BASE_URL=http://localhost:8000/v1
ADSP_LLM_MODEL=
ADSP_LLM_API_KEY=EMPTY

# Optional generation knobs
ADSP_LLM_TEMPERATURE=0.2
ADSP_LLM_MAX_TOKENS=512
ADSP_LLM_TIMEOUT=60

# Orchestrator relevance filtering (history + retrieved context)
ADSP_CONTEXT_FILTER_ENABLED=true
ADSP_CONTEXT_FILTER_BACKEND=heuristic
ADSP_CONTEXT_FILTER_MAX_HISTORY=10
ADSP_CONTEXT_FILTER_MAX_BLOCKS=10
ADSP_CONTEXT_FILTER_MIN_COVERAGE=0.2
ADSP_CONTEXT_FILTER_TIMEOUT=30

# OpenAI-compatible context filter model settings (only used when ADSP_CONTEXT_FILTER_BACKEND=openai)
# Defaults to ADSP_LLM_* / VLLM_* if left blank.
ADSP_CONTEXT_FILTER_BASE_URL=
ADSP_CONTEXT_FILTER_MODEL=
ADSP_CONTEXT_FILTER_API_KEY=

# Persona data locations (override if you store outputs elsewhere)
ADSP_PERSONAS_DIR=data/processed/personas/individual
ADSP_PERSONA_TRAITS_DIR=data/processed/personas/common_traits

# Persona extraction pipeline (scripts/run_persona_extraction.py)
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=
VLLM_API_KEY=EMPTY

# Optional reasoning enrichment model (can reuse the same endpoint)
REASONING_BASE_URL=http://localhost:8000/v1
REASONING_MODEL=
REASONING_API_KEY=EMPTY
